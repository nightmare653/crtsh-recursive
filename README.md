# ğŸ“ Recursive crt.sh Subdomain Enumerator

### A Bash tool for extracting subdomains & wildcard roots using crt.sh â€” with recursion, retries, and rate limiting

## ğŸš€ Overview

This script performs **certificate transparency enumeration** using `crt.sh` and automatically:

âœ… Queries `crt.sh` for `*.domain.com`
âœ… Extracts `name_value` entries via `jq`
âœ… Splits results into:

* **Concrete subdomains** â†’ `subs.txt`
* **Wildcard-derived roots** â†’ `wildcards_clean.txt`

âœ… Recursively re-queries newly discovered wildcard roots
âœ… Avoids duplicate lookups using a `seen` associative array
âœ… Saves results in **per-domain folders**
âœ… Supports retry logic and rate-limiting

This makes it useful for reconnaissance, bug bounty automation, red teaming, and passive mapping of an organizationâ€™s attack surface.

---

## ğŸ§° Features

### âœ… Fully passive (no DNS / HTTP probing)

### âœ… Recursive wildcard expansion

### âœ… Per-domain output directories

### âœ… Curl retry & timeout handling

### âœ… JSON parsing with jq

### âœ… Skip reruns when data already exists

### âœ… Environment-configurable behavior

---

## ğŸ“¦ Requirements

Make sure the following binaries are installed:

```bash
curl
jq
```

Install on Debian/Ubuntu/Kali:

```bash
sudo apt install -y curl jq
```

---

## ğŸ“„ Input Format

Create a file named `domains.txt` (or any file of your choice):

```
example.com
hackerone.com
bugcrowd.com
# comments and empty lines are ignored
```

---

## â–¶ï¸ Usage

### **Basic usage**

```bash
./crt_recursive.sh
```

### **Using a custom input file**

```bash
./crt_recursive.sh targets.txt
```

### **Make it executable (first time only)**

```bash
chmod +x crt_recursive.sh
```

---

## âš™ï¸ Optional Environment Variables

| Variable             | Default | Purpose                                   |
| -------------------- | ------- | ----------------------------------------- |
| `RATE_LIMIT_SECONDS` | `1`     | Delay between crt.sh requests             |
| `MAX_RETRIES`        | `3`     | Retry count for failed curl attempts      |
| `SKIP_DONE`          | `1`     | Skip domains if `subs.txt` already exists |

### Examples:

#### Slow it down for safety:

```bash
RATE_LIMIT_SECONDS=2 ./crt_recursive.sh
```

#### Force full reprocessing:

```bash
SKIP_DONE=0 ./crt_recursive.sh
```

#### Increase robustness:

```bash
MAX_RETRIES=5 ./crt_recursive.sh
```

#### Combine all:

```bash
RATE_LIMIT_SECONDS=2 MAX_RETRIES=5 SKIP_DONE=0 ./crt_recursive.sh targets.txt
```

---

## ğŸ“ Output Structure

For each domain processed, a directory is created:

```
example.com/
 â”œâ”€ subs.txt
 â””â”€ wildcards_clean.txt
```

### `subs.txt` contains:

âœ… Non-wildcard resolved subdomains
Example:

```
api.example.com
login.example.com
assets.foo.example.com
```

### `wildcards_clean.txt` contains:

âœ… Wildcard-derived roots queued for recursion
Example:

```
foo.example.com
bar.foo.example.com
ae.example.com
```

---

## ğŸ” How It Works Internally (Summary)

1. Reads input domains line-by-line
2. Creates per-domain workspace
3. Seeds a queue with the top-level domain
4. Performs BFS-style recursion:

   * queries crt.sh
   * extracts names
   * sends wildcard-derived entries back into queue
5. Dedupe and save results

---

## ğŸ›¡ Ethical Usage Notice

This tool is intended for:

âœ… penetration testers
âœ… bug bounty researchers
âœ… asset inventory teams
âœ… defensive reconnaissance

**Do not use against systems without authorization.**

---

## ğŸ§ª Next Steps / Recommended Pipeline Integration

After collecting:

```bash
cat */subs.txt | sort -u > all_subs.txt
```


## ğŸ‘¥ Contributors

<a href="https://github.com/Md-Yousuf-Hussain">
  <img src="https://avatars.githubusercontent.com/Md-Yousuf-Hussain" width="60" />
</a>
<a href="https://github.com/nightmare653">
  <img src="https://avatars.githubusercontent.com/nightmare653" width="60" />
</a>

## â­ If You Find This Useful

Please **star the repository** â€” it helps visibility!

---

